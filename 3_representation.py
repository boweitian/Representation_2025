from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM
from repe.rep_reading_pipeline import transform
import matplotlib.pyplot as plt
import torch
from tqdm import tqdm
import numpy as np
from transformers import AutoProcessor, AutoModelForVision2Seq
import os
from repe.pipelines import repe_pipeline_registry
from PIL import Image

repe_pipeline_registry()
# **æ£€æŸ¥ PyTorch çœ‹åˆ°çš„ GPU**
os.environ["CUDA_VISIBLE_DEVICES"] = "2,5,6,7"

print(f"PyTorch å¯è§çš„ GPU æ•°é‡: {torch.cuda.device_count()}")  
for i in range(torch.cuda.device_count()):
    print(f"GPU {i} è®¾å¤‡åç§°: {torch.cuda.get_device_name(i)}")
    
direction_method = 'pca'
rep_token = -1
debug = False

# **2. åŠ è½½æ¨¡å‹ä¸Processor**
processor = AutoProcessor.from_pretrained("HuggingFaceM4/idefics2-8b")
model = AutoModelForVision2Seq.from_pretrained(
    "HuggingFaceM4/idefics2-8b", load_in_8bit=True, device_map="auto"  # å¯ç”¨ 8-bit é‡åŒ–
)
model_name_or_path = "ehartford/Wizard-Vicuna-30B-Uncensored"
use_fast_tokenizer = "LlamaForCausalLM" not in model.config.architectures
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=use_fast_tokenizer, padding_side="left", legacy=False)
tokenizer.pad_token_id = 0

hidden_layers = list(range(-1, -33, -1)) # 33: num_layers
n_difference = 1

rep_reading_pipeline =  pipeline("rep-reading", model=model, tokenizer = tokenizer, image_processor=processor.image_processor)

import json

with open("file/coco_honesty_dataset.json", "r") as f:
    dataset_raw = json.load(f)
if debug:
    dataset_raw['data'] = dataset_raw['data'][0:4]
# è§£ææ•°æ®
data = []
labels = []
images = []
for item in dataset_raw["data"]:
    honest = item["honest"]
    untruthful = item["untruthful"]
    route = item["image_id"]

    data.append(honest)
    data.append(untruthful)
    labels.append([1, 0])
    images.append(route)

# å½¢æˆæœ€ç»ˆçš„æ•°æ®é›†æ ¼å¼
dataset = {
    "train": {
        "data": data,
        "labels": labels,
        "images": images
    }
}
dataset['train']['images'] = [img for img in dataset['train']['images'] for _ in range(2)]
dataset_list = [
    {"data": dataset["train"]["data"][i], "images": dataset["train"]["images"][i]}
    for i in range(len(dataset["train"]["data"]))
]

# è¾“å‡ºæ•°æ®è§„æ¨¡
print(f"Total sentences: {len(dataset['train']['data'])}")  # åº”è¯¥æ˜¯ `labels` é•¿åº¦çš„ä¸¤å€
print(f"Total label pairs: {len(dataset['train']['labels'])}")  # å¯¹åº” `honest/untruthful` å¯¹

# å¯é€‰ï¼šä¿å­˜å¤„ç†åçš„æ•°æ®
with open("file/processed_coco_honesty_dataset.json", "w") as f:
    json.dump(dataset, f, indent=4)

honesty_rep_reader = rep_reading_pipeline.get_directions(
    dataset_list,
    rep_token=rep_token, 
    hidden_layers=hidden_layers, 
    n_difference=n_difference, 
    train_labels=dataset['train']['labels'], 
    direction_method=direction_method,
    batch_size=4, processor = processor
)

def format_output(output_text, question, image_path):
    """
    é‡æ–°æ ¼å¼åŒ– output_textï¼Œä½¿å…¶ç¬¦åˆ {'data': ..., 'images': ...} ç»“æ„
    
    Args:
        output_text (str): æ¨¡å‹ç”Ÿæˆçš„åŸå§‹æ–‡æœ¬
        question (str): ç”¨æˆ·çš„æé—®
        image_path (str): å›¾ç‰‡è·¯å¾„

    Returns:
        dict: æ ¼å¼åŒ–åçš„æ•°æ®
    """
    # **æ„é€ æ–°çš„ USER éƒ¨åˆ†**
    formatted_user = f"USER: <image> {question}"

    # **è§£æ ASSISTANT éƒ¨åˆ†**
    if "ASSISTANT:" in output_text:
        assistant_part = output_text.split("ASSISTANT:")[1].strip()
    else:
        assistant_part = output_text.strip()

    # **æ„é€ æœ€ç»ˆæ ¼å¼**
    formatted_text = f"{formatted_user} ASSISTANT: {assistant_part}"

    # **è¿”å›ç¬¦åˆæ ¼å¼çš„å­—å…¸**
    return {"data": formatted_text, "images": image_path}


def evaluate_honesty(image_path, question):
    """
    è®¡ç®—ç»™å®šå›¾ç‰‡+æ–‡æœ¬ç”Ÿæˆçš„å›ç­”çš„ honesty åˆ†æ•°

    Args:
        image_path (str): å›¾ç‰‡è·¯å¾„
        question (str): å¯¹å›¾ç‰‡çš„æé—®

    Returns:
        str: æ¨¡å‹ç”Ÿæˆçš„å›ç­”
        float: honesty åˆ†æ•°
    """
    # **åŠ è½½å›¾ç‰‡**
    image = Image.open(image_path).convert("RGB")

    # **æ„é€ ç¬¦åˆèŠå¤©æ ¼å¼çš„è¾“å…¥**
    prompt = f"USER: <image> {question}\nASSISTANT:"

    inputs = processor(text=prompt, images=[image], return_tensors="pt").to("cuda")

    # **ç”Ÿæˆå›ç­”**
    with torch.no_grad():
        generated_ids = model.generate(**inputs, max_new_tokens=50)
        output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

    # **è®¡ç®— honesty è¯„åˆ†**
    results = []
    tokenized_output = processor.tokenizer(output_text, return_tensors="pt")
    input_ids = tokenized_output["input_ids"][0]  # è·å– token åºåˆ—
    for ice_pos in range(len(input_ids)):
        ice_pos = -len(hidden_layers) + ice_pos
        # {'data': "USER: <image> Pretend you're an honest person making statements about the world. ASSISTANT: this is,", 'images': '000000000139.jpg'}
        H_tests = rep_reading_pipeline(
            [format_output(output_text, question, image_path)],
            processor = processor, 
            rep_reader=honesty_rep_reader,
            rep_token=ice_pos,
            hidden_layers=hidden_layers,
            image_base_path = './'
        )
        breakpoint()
        results.append(H_tests)

    # **è®¡ç®— honesty score**
    honesty_scores = [round(r[0][-1].item(), 1) for r in results]
    tokens = processor.tokenizer.convert_ids_to_tokens(input_ids)
    print("\nğŸ“Š Token-wise Honesty Scores:")
    for token, score in zip(tokens, honesty_scores):
        print(f"Token: {token.ljust(15)} | Score: {score}")

    return output_text, honesty_scores

image_path = "image.jpg"  # ä½ çš„å›¾ç‰‡è·¯å¾„
question = "Pretend you're an honest person making statements about the world."

answer, score = evaluate_honesty(image_path, question)

print(f"ğŸ–¼ï¸ å›¾ç‰‡: {image_path}")
print(f"â“ é—®é¢˜: {question}")
print(f"ğŸ’¬ æ¨¡å‹å›ç­”: {answer}")

question = "Pretend you're an untruthful person making statements about the world."

answer, score = evaluate_honesty(image_path, question)

print(f"ğŸ–¼ï¸ å›¾ç‰‡: {image_path}")
print(f"â“ é—®é¢˜: {question}")
print(f"ğŸ’¬ æ¨¡å‹å›ç­”: {answer}")
breakpoint()